{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch API / Specified Language Transcription\n",
        "\n",
        "This notebook uses the batch API to analyze emotion in a language of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utilities import print_emotions\n",
        "\n",
        "from hume import HumeBatchClient, TranscriptionConfig\n",
        "from hume.models.config import ProsodyConfig, LanguageConfig"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Submit a batch job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running... Job(id=\"59088371-329b-4dfe-ab30-6cc046ce5fd9\")\n",
            "Job completed with status:  BatchJobStatus.COMPLETED\n"
          ]
        }
      ],
      "source": [
        "client = HumeBatchClient(\"BvwDPKJ6eevK678fTrO0rQE39eamDj9HbxkNN2mjtvVLLnAo\")\n",
        "\n",
        "urls = [\"https://github.com/S-abk/Dual/raw/main/hume_test.mp3\"]\n",
        "prosody_config = ProsodyConfig(granularity=\"conversational_turn\", identify_speakers=True)\n",
        "# transcription_config = TranscriptionConfig()  # Will detect Japanese\n",
        "job = client.submit_job(urls, [prosody_config])\n",
        "\n",
        "print(\"Running...\", job)\n",
        "job.await_complete()\n",
        "print(\"Job completed with status: \", job.get_status())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print out predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Joy: 0.029002\n",
            "- Sadness: 0.024817\n",
            "- Anger: 0.177202\n"
          ]
        }
      ],
      "source": [
        "from utilities import print_emotions\n",
        "\n",
        "full_predictions = job.get_predictions()\n",
        "for source in full_predictions:\n",
        "    source_name = source[\"source\"][\"url\"]\n",
        "    predictions = source[\"results\"][\"predictions\"]\n",
        "    for prediction in predictions:\n",
        "        prosody_predictions = prediction[\"models\"][\"prosody\"][\"grouped_predictions\"]\n",
        "        for prosody_prediction in prosody_predictions:\n",
        "            for segment in prosody_prediction[\"predictions\"][:1]:\n",
        "                print_emotions(segment[\"emotions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "803ebf602b46e67aaba753b211048224996199ded4fc88a644a85d99d245b351"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
